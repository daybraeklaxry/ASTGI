#!/bin/bash

# =====================================================================================
#                 Warpformer åœ¨ MIMIC-III ä¸Šçš„è¶…å‚æ•°æœç´¢è„šæœ¬ (é«˜æ•ˆGPUåˆ©ç”¨)
# =====================================================================================

# --- 1. GPU é…ç½® ---
# åœ¨è¿™é‡ŒæŒ‡å®šä½ æƒ³ä½¿ç”¨çš„GPUç¼–å·ï¼Œç”¨é€—å·éš”å¼€ï¼Œä¾‹å¦‚ "0,1,2,3" æˆ– "4,5,6,7"
GPU_IDS="0,1,2,5,6,7"

# å°†GPU_IDSå­—ç¬¦ä¸²è½¬æ¢ä¸ºbashæ•°ç»„
IFS=',' read -r -a GPUS <<< "$GPU_IDS"
NUM_GPUS=${#GPUS[@]}

# [æ ¸å¿ƒæœºåˆ¶] ä½¿ç”¨å…³è”æ•°ç»„æ¥è¿½è¸ªæ¯ä¸ªGPUä¸Šè¿è¡Œçš„è¿›ç¨‹ID (PID)
# é”®: GPU ID, å€¼: ä»»åŠ¡çš„ PID
declare -A gpu_pids
for gpu in "${GPUS[@]}"; do
    gpu_pids[$gpu]=""
done

echo "ğŸš€ å°†åœ¨ ${NUM_GPUS} ä¸ªGPU (${GPUS[*]}) ä¸Šå¹¶è¡Œæ‰§è¡Œ Warpformer ä»»åŠ¡ï¼Œé‡‡ç”¨åŠ¨æ€è°ƒåº¦ç­–ç•¥ã€‚"

# --- 2. å›ºå®šå‚æ•° (åŸºäºMIMIC-IIIæ•°æ®é›†å’Œå…¬å¹³æ¯”è¾ƒåŸåˆ™) ---
model_name="Warpformer"
dataset_root_path="storage/datasets/MIMIC_III"
dataset_name="MIMIC_III"
seq_len=72
pred_len=3
enc_in=96
c_out=96

# --- 3. Warpformer è¶…å‚æ•°æœç´¢ç©ºé—´ (åŸºäºç­–ç•¥åˆ†æ) ---

# [ç­–ç•¥] d_model: æ¨¡å‹çš„æ ¸å¿ƒç»´åº¦ï¼Œæ˜¯æ€§èƒ½å’Œå¤æ‚åº¦çš„å…³é”®ã€‚æ¢ç´¢ä»è¾ƒå°åˆ°è¾ƒå¤§çš„èŒƒå›´ã€‚
d_models=(64 128 256)

# [ç­–ç•¥] batch_size: è€ƒè™‘åˆ°d_modelå¢å¤§å¯èƒ½å¢åŠ æ˜¾å­˜æ¶ˆè€—ï¼Œæ¢ç´¢ 16 å’Œ 32 ä¸¤ä¸ªå¸¸ç”¨é€‰é¡¹ã€‚
batch_sizes=(16 32)

# [ç­–ç•¥] learning_rate: å­¦ä¹ ç‡æ˜¯ä¼˜åŒ–çš„å…³é”®ã€‚é€‰æ‹©ä¸€ä¸ªç»è¿‡éªŒè¯çš„ã€åœ¨ Transformer ç±»æ¨¡å‹ä¸Šè¡¨ç°è‰¯å¥½çš„èŒƒå›´ã€‚
lrs=(0.001)

# [ç­–ç•¥] dropout: Transformer ä¸­æ ‡å‡†çš„æ­£åˆ™åŒ–æ–¹æ³•ï¼Œé˜²æ­¢è¿‡æ‹Ÿåˆã€‚
dropouts=(0.0 0.1 0.2)

# [ç­–ç•¥] n_layers: Encoder å±‚æ•°ï¼Œå†³å®šäº†æ¨¡å‹çš„æ·±åº¦å’Œæ•æ‰å¤æ‚ä¾èµ–çš„èƒ½åŠ›ã€‚
n_layers_options=(1 2 3)

# [ç­–ç•¥] n_heads: å¤šå¤´æ³¨æ„åŠ›æœºåˆ¶çš„å¤´æ•°ï¼Œå…è®¸æ¨¡å‹åœ¨ä¸åŒå­ç©ºé—´ä¸­å…³æ³¨ä¿¡æ¯ã€‚
n_heads_options=(2 4 8)


# --- 4. éšæœºæœç´¢è®¾ç½® ---
# æ€»å…±å¸Œæœ›è¿è¡Œçš„å®éªŒç»„æ•°
TOTAL_RUNS=256

# --- [æ ¸å¿ƒæœºåˆ¶] åŠ¨æ€å¯»æ‰¾ç©ºé—²GPUçš„å‡½æ•° ---
# (æ­¤å‡½æ•°ä¸æ‚¨æä¾›çš„è„šæœ¬å®Œå…¨ç›¸åŒï¼ŒåŠŸèƒ½æ˜¯æ‰¾åˆ°ä¸€ä¸ªå½“å‰æ²¡æœ‰ä»»åŠ¡è¿è¡Œçš„GPU)
find_free_gpu() {
    local free_gpu_id=""
    # å¾ªç¯ç›´åˆ°æ‰¾åˆ°ä¸€ä¸ªç©ºé—²çš„GPU
    while [[ -z "$free_gpu_id" ]]; do
        for gpu_id in "${GPUS[@]}"; do
            pid=${gpu_pids[$gpu_id]}
            # å¦‚æœPIDä¸ºç©ºæˆ–è¯¥è¿›ç¨‹ä¸å­˜åœ¨ï¼Œåˆ™è®¤ä¸ºGPUç©ºé—²
            if [[ -z "$pid" ]] || ! kill -0 "$pid" 2>/dev/null; then
                free_gpu_id=$gpu_id
                unset gpu_pids[$gpu_id] # æ¸…é™¤æ—§çš„ã€å·²ç»“æŸçš„PIDè®°å½•
                break
            fi
        done
        # å¦‚æœæ‰€æœ‰GPUéƒ½åœ¨å¿™ï¼Œç­‰å¾…ä»»ä½•ä¸€ä¸ªåå°ä»»åŠ¡ç»“æŸ
        if [[ -z "$free_gpu_id" ]]; then
            wait -n
        fi
    done
    echo "$free_gpu_id"
}


echo "ğŸš€ å¼€å§‹ Warpformer åœ¨ MIMIC-III ä¸Šçš„éšæœºæœç´¢ï¼Œæ€»å…±å°†è¿è¡Œ ${TOTAL_RUNS} ç»„å®éªŒ..."

# --- 5. éšæœºæœç´¢ä¸»å¾ªç¯ ---
for (( i=1; i<=${TOTAL_RUNS}; i++ )); do

  # --- éšæœºé‡‡æ ·è¶…å‚æ•° ---
  dm=${d_models[$((RANDOM % ${#d_models[@]}))]}
  bs=${batch_sizes[$((RANDOM % ${#batch_sizes[@]}))]}
  lr=${lrs[$((RANDOM % ${#lrs[@]}))]}
  dp=${dropouts[$((RANDOM % ${#dropouts[@]}))]}
  n_layers=${n_layers_options[$((RANDOM % ${#n_layers_options[@]}))]}
  n_heads=${n_heads_options[$((RANDOM % ${#n_heads_options[@]}))]}


  # --- [æ ¸å¿ƒæœºåˆ¶] GPU åŠ¨æ€åˆ†é… ---
  gpu_id=$(find_free_gpu)

  # --- æ„å»ºå”¯ä¸€çš„æ¨¡å‹ID (åŒ…å«Warpformerå…³é”®å‚æ•°) ---
  model_id="${model_name}_${dataset_name}_sl${seq_len}_pl${pred_len}_dm${dm}_L${n_layers}_nh${n_heads}_dp${dp}_lr${lr}_bs${bs}_run${i}"

  echo "-----------------------------------------------------------------------"
  echo "ğŸ“ˆ å¯åŠ¨ä»»åŠ¡ [${i}/${TOTAL_RUNS}] -> åŠ¨æ€åˆ†é…è‡³ç©ºé—² GPU ${gpu_id}"
  echo "   Arch: d_model=${dm}, n_layers=${n_layers}, n_heads=${n_heads}, dropout=${dp}"
  echo "   Train: batch_size=${bs}, learning_rate=${lr}"
  echo "   Model ID: ${model_id}"
  echo "-----------------------------------------------------------------------"

  # --- åœ¨åå°å¯åŠ¨è®­ç»ƒä»»åŠ¡ (æ³¨æ„å‚æ•°å·²æ›´æ–°ä¸ºWarpformerçš„) ---
  (
    # å°†ä»»åŠ¡ç»‘å®šåˆ°æ‰¾åˆ°çš„ç©ºé—²GPUä¸Š
    CUDA_VISIBLE_DEVICES=${gpu_id} python main.py \
      --is_training 1 \
      --model_id "$model_id" \
      --model_name "$model_name" \
      --dataset_root_path "$dataset_root_path" \
      --dataset_name "$dataset_name" \
      --features M \
      --seq_len "$seq_len" \
      --pred_len "$pred_len" \
      --enc_in "$enc_in" \
      --c_out "$c_out" \
      --loss "MSE" \
      --train_epochs 300 \
      --patience 5 \
      --val_interval 1 \
      --itr 5 \
      --batch_size "$bs" \
      --learning_rate "$lr" \
      --d_model "$dm" \
      --n_heads "$n_heads" \
      --n_layers "$n_layers" \
      --dropout "$dp"
  ) & # ä½¿ç”¨ '&' å°†å‘½ä»¤ç½®äºåå°æ‰§è¡Œ

  # --- [æ ¸å¿ƒæœºåˆ¶] è®°å½•æ–°ä»»åŠ¡çš„ PID ---
  new_pid=$!
  gpu_pids[$gpu_id]=$new_pid
  echo "   ä»»åŠ¡å·²å¯åŠ¨ï¼ŒPID: ${new_pid}ï¼Œå·²ç»‘å®šè‡³ GPU ${gpu_id}"

  sleep 1 # çŸ­æš‚ä¼‘çœ ï¼Œç¡®ä¿æ—¥å¿—é¡ºåºå’ŒPIDæ­£ç¡®æ•è·

done

echo "âœ… æ‰€æœ‰ ${TOTAL_RUNS} ç»„ä»»åŠ¡å·²å¯åŠ¨ï¼Œç­‰å¾…æœ€åæ‰¹æ¬¡çš„ä»»åŠ¡æ‰§è¡Œå®Œæ¯•..."
wait # ç­‰å¾…æ‰€æœ‰åå°å¯åŠ¨çš„å­è¿›ç¨‹å…¨éƒ¨ç»“æŸ
echo "ğŸ‰ğŸ‰ğŸ‰ Warpformer åœ¨ MIMIC-III ä¸Šçš„éšæœºæœç´¢ä»»åŠ¡å·²å…¨éƒ¨å®Œæˆï¼ğŸ‰ğŸ‰ğŸ‰"